{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "word-embeddings.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "0b591df097dd452daca79306abcd3f79": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_fb59e680d06f4d438d7c3e4cea592b75",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_c45252039ecd464596a5c2ce83b58e02",
              "IPY_MODEL_4d67c47413e74cca9353e304944f5c22"
            ]
          },
          "model_module_version": "1.5.0"
        },
        "fb59e680d06f4d438d7c3e4cea592b75": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          },
          "model_module_version": "1.2.0"
        },
        "c45252039ecd464596a5c2ce83b58e02": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_7b97c0edb8f742babe70de9507afb9fe",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 231508,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 231508,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_fcd212aa59fe4e38925c4d57ac45e2d3"
          },
          "model_module_version": "1.5.0"
        },
        "4d67c47413e74cca9353e304944f5c22": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_92d33031edb04a9f80891cba9dddd9df",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 232k/232k [00:00&lt;00:00, 675kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_a900bc08c9944d8b931c0c64f5371082"
          },
          "model_module_version": "1.5.0"
        },
        "7b97c0edb8f742babe70de9507afb9fe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          },
          "model_module_version": "1.5.0"
        },
        "fcd212aa59fe4e38925c4d57ac45e2d3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          },
          "model_module_version": "1.2.0"
        },
        "92d33031edb04a9f80891cba9dddd9df": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          },
          "model_module_version": "1.5.0"
        },
        "a900bc08c9944d8b931c0c64f5371082": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          },
          "model_module_version": "1.2.0"
        },
        "1ae7a66074b24b30b7b8d47b75104c7f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_16a736e460f749c9a1c035723a1ad201",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_7843040f735546afb64c90602c1c8a0b",
              "IPY_MODEL_596cc22cc85948238fa53d923227f1ae"
            ]
          },
          "model_module_version": "1.5.0"
        },
        "16a736e460f749c9a1c035723a1ad201": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          },
          "model_module_version": "1.2.0"
        },
        "7843040f735546afb64c90602c1c8a0b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_023206090efd43f3bf81dfddf342e5c1",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 4,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 4,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_a750268e28d24240bf36532404abc1fa"
          },
          "model_module_version": "1.5.0"
        },
        "596cc22cc85948238fa53d923227f1ae": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_98985960e55f438ba8dbbf77c50ed47b",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 4/4 [00:00&lt;00:00, 63.59it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_c81ccc42ccb245a3b3c965b237576550"
          },
          "model_module_version": "1.5.0"
        },
        "023206090efd43f3bf81dfddf342e5c1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          },
          "model_module_version": "1.5.0"
        },
        "a750268e28d24240bf36532404abc1fa": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          },
          "model_module_version": "1.2.0"
        },
        "98985960e55f438ba8dbbf77c50ed47b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          },
          "model_module_version": "1.5.0"
        },
        "c81ccc42ccb245a3b3c965b237576550": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          },
          "model_module_version": "1.2.0"
        },
        "2899a7fc90ab4541af179a63abba0b39": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_700b9b4369d04c7baa90551057950298",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_a93285635aef433281557db177e019af",
              "IPY_MODEL_dcf81c767ad84cb9b2c305d1d94743e7"
            ]
          },
          "model_module_version": "1.5.0"
        },
        "700b9b4369d04c7baa90551057950298": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          },
          "model_module_version": "1.2.0"
        },
        "a93285635aef433281557db177e019af": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_6898eb8c7ccd4bc59ba327b244edf4af",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 1,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_6e779a45d40f408a9a7419a11101e0b4"
          },
          "model_module_version": "1.5.0"
        },
        "dcf81c767ad84cb9b2c305d1d94743e7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_3108385d70a24cc8a9fde1f4c8c91d19",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 1/1 [00:00&lt;00:00,  1.26it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_aea2a412a09f46d2b68a36c23a3577f3"
          },
          "model_module_version": "1.5.0"
        },
        "6898eb8c7ccd4bc59ba327b244edf4af": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          },
          "model_module_version": "1.5.0"
        },
        "6e779a45d40f408a9a7419a11101e0b4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          },
          "model_module_version": "1.2.0"
        },
        "3108385d70a24cc8a9fde1f4c8c91d19": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          },
          "model_module_version": "1.5.0"
        },
        "aea2a412a09f46d2b68a36c23a3577f3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          },
          "model_module_version": "1.2.0"
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZYwcIXq4t7cg"
      },
      "source": [
        "#Word embeddings in 2020. Review with code  examples\n",
        "\n",
        "by [Rostyslav Neskorozhenyi](https://www.linkedin.com/in/slanj)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uabj5jkUt_hK"
      },
      "source": [
        "In this article we will study word embeddings - digital representation of words suitable for processing by machine learning algorithms. \n",
        "\n",
        "Originally I created this article as a general overview and compilation of current approaches to word embeddings in 2020, which our [AI Labs](http://ai-labs.org/) team could use from time to time as a quick refresher. I hope that my article will be useful to a wider circle of data scientists and developers. Each word embedding method in the article has a (very) short description, links for further study, and code examples in Python. All code is packed as [Google Colab Notebook](https://colab.research.google.com/drive/1N7HELWImK9xCYheyozVP3C_McbiRo1nb). So let's begin.\n",
        "\n",
        "According to Wikipedia, **Word embedding** is the collective name for a set of language modeling and feature learning techniques in natural language processing (NLP) where words or phrases from the vocabulary are mapped to vectors of real numbers."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "knWTPeFGvCVr"
      },
      "source": [
        "## One-hot or CountVectorizing\n",
        "\n",
        "The most basic method for transforming words into vectors is to count occurrence of each word in each document. Such approach is called countvectorizing or one-hot encoding.\n",
        "\n",
        "The main principle of this method is to collect a set of documents (they can be words, sentences, paragraphs or even articles) and count the occurrence of every word in each document. Strictly speaking, the columns of the resulting matrix are words and the rows are documents."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CqL-rowBt3FB"
      },
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "# create CountVectorizer object\n",
        "vectorizer = CountVectorizer()\n",
        "corpus = [\n",
        "          'Text of the very first new sentence with the first words in sentence.',\n",
        "          'Text of the second sentence.',\n",
        "          'Number three with lot of words words words.',\n",
        "          'Short text, less words.',\n",
        "]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0nz67PMDv4-1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        },
        "outputId": "630d6f22-09a1-4017-d562-2f21de063c88"
      },
      "source": [
        "corpus"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Text of the very first new sentence with the first words in sentence.',\n",
              " 'Text of the second sentence.',\n",
              " 'Number three with lot of words words words.',\n",
              " 'Short text, less words.']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jp5Ylyahv-Sx",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "outputId": "fade7f2d-e79a-43d1-aa03-4fa7798ec299"
      },
      "source": [
        "# learn the vocabulary and store CountVectorizer sparse matrix in term_frequencies\n",
        "term_frequencies = vectorizer.fit_transform(corpus) \n",
        "vocab = vectorizer.get_feature_names()\n",
        "vocab"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['first',\n",
              " 'in',\n",
              " 'less',\n",
              " 'lot',\n",
              " 'new',\n",
              " 'number',\n",
              " 'of',\n",
              " 'second',\n",
              " 'sentence',\n",
              " 'short',\n",
              " 'text',\n",
              " 'the',\n",
              " 'three',\n",
              " 'very',\n",
              " 'with',\n",
              " 'words']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n9Wzj12tFU4-",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        },
        "outputId": "7662230b-8903-4f0b-fbb2-b50539dd53e2"
      },
      "source": [
        "term_frequencies = term_frequencies.toarray() # convert sparse matrix to numpy array\n",
        "term_frequencies "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[2, 1, 0, 0, 1, 0, 1, 0, 2, 0, 1, 2, 0, 1, 1, 1],\n",
              "       [0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0],\n",
              "       [0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 3],\n",
              "       [0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7AMSth6SJ-VL",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 301
        },
        "outputId": "4fb141cb-ad88-4bb5-e896-79ba5d7274c0"
      },
      "source": [
        "import seaborn as sns\n",
        "sns.heatmap(term_frequencies, annot=True, cbar = False, xticklabels = vocab);"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5swG8_LdwPEN",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "f1200019-3098-4d9e-bc3e-82dde19f5985"
      },
      "source": [
        "# Convert another document with countvectorizing\n",
        "vectorizer.transform(['A new new sentence.']).toarray()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0, 0, 0, 0, 2, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CKO-WI3IEuaR"
      },
      "source": [
        "Another approach in countvectorizing is just to place 1 if the word is found in the document (no matter how often) and 0 if the word is not found in the document. In this case we get real 'one-hot' encoding."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cd8wwfuWED1w",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        },
        "outputId": "7c0b894b-544f-4220-b972-251acad6b7c5"
      },
      "source": [
        "one_hot_vectorizer = CountVectorizer(binary=True)\n",
        "one_hot = one_hot_vectorizer.fit_transform(corpus).toarray()\n",
        "one_hot"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1],\n",
              "       [0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0],\n",
              "       [0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1],\n",
              "       [0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HMr0ixndJlL7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 318
        },
        "outputId": "2ed28df2-136a-4a03-80aa-ad8982399b9a"
      },
      "source": [
        "sns.heatmap(one_hot, annot=True, cbar = False, xticklabels = vocab)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f99ba578198>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5yiZ6Ua4w5u2"
      },
      "source": [
        "## TF-IDF encoding\n",
        "\n",
        "With a large corpus of documents some words like ‘a’, ‘the’, ‘is’, etc. occur very frequently but they don’t carry a lot of information. Using one-hot encoding approach we can decide that these words are important because they appear in many documents. One of the ways to solve this problem is stopwords filtering, but this solution is discrete and not flexible.\n",
        "\n",
        "TF-IDF (term frequency - inverse document frequency) can deal with this problem better. TF-IDF lowers the weight of commonly used words and raises the weight of rare words that occur only in current document. TF-IDF formula looks like this:\n",
        "<br><br>\n",
        "\n",
        "$tfidf(term, document)= tf(term, document) \\cdot idf(term)$\n",
        "\n",
        "<br>\n",
        "Where TF is calculated by dividing number of times the word occurs in the document by the total number of words in the document\n",
        "\n",
        "$tf(term, document)= \\frac{n_i}{\\sum_{k=1}^W n_k}$\n",
        "\n",
        "IDF (inverse document frequency), interpreted like inversed number of documents, in which the term we’re interested in occurs. N - number of documents, n(t) - number of documents with current word or term t.\n",
        "\n",
        "\n",
        "$idf(term) = \\log {\\frac{N}{n_t}} $\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pRF9_B5lwURy"
      },
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "import seaborn as sns\n",
        "\n",
        "corpus = [\n",
        "          'Time flies like an arrow.',\n",
        "          'Fruit flies like a banana.'\n",
        "]\n",
        "\n",
        "vocab = ['an', 'arrow', 'banana', 'flies', 'fruit', 'like', 'time']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uckXLvR0DKIm",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        },
        "outputId": "3d974b25-6e63-4b06-f614-e380843a8f76"
      },
      "source": [
        "tfidf_vectorizer = TfidfVectorizer()\n",
        "tfidf = tfidf_vectorizer.fit_transform(corpus).toarray()\n",
        "tfidf"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.49922133, 0.49922133, 0.        , 0.35520009, 0.        ,\n",
              "        0.35520009, 0.49922133],\n",
              "       [0.        , 0.        , 0.57615236, 0.40993715, 0.57615236,\n",
              "        0.40993715, 0.        ]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rI8h6WGCDgY_",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "outputId": "d998e939-e3cc-4e9c-af5e-8f3cf068ff7f"
      },
      "source": [
        "sns.heatmap(tfidf, annot=True, cbar = False, xticklabels = vocab)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f99ba3e8978>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P8IxcZQGTGb6"
      },
      "source": [
        "## Word2Vec and GloVe"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pHdtizR4T1d_"
      },
      "source": [
        "The most commonly used models for word embeddings are [word2vec](https://github.com/dav/word2vec/) and [GloVe](https://nlp.stanford.edu/projects/glove/) which are both unsupervised approaches based on the distributional hypothesis (words that occur in the same contexts tend to have similar meanings).\n",
        "\n",
        "Word2Vec word embeddings are vector representations of words, \n",
        "that are typically learnt by an unsupervised model when fed \n",
        "with large amounts of text as input (e.g. Wikipedia, science, news, articles etc.). These representation of words capture semantic similarity between words among other properties. Word2Vec word embeddings are learnt in a such way, that [distance](https://en.wikipedia.org/wiki/Euclidean_distance) between vectors for words with close meanings (\"king\" and \"queen\" for example) are closer than distance for words with complety different meanings (\"king\" and \"carpet\" for example).\n",
        "\n",
        "![Замещающий текст](https://developers.google.com/machine-learning/crash-course/images/linear-relationships.svg)\n",
        "Image from [developers.google.com](https://developers.google.com/machine-learning/crash-course/embeddings/translating-to-a-lower-dimensional-space)\n",
        "\n",
        "Word2Vec vectors even allow some mathematic operations on vectors. For example, in this operation we are using word2vec vectors for each word:\n",
        "\n",
        "**king - man + woman = queen**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dfo-brEm-STg",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 208
        },
        "outputId": "0ea5cabd-27b5-4a44-cce4-0b6a5c708da9"
      },
      "source": [
        "# Download Google Word2Vec embeddings https://code.google.com/archive/p/word2vec/\n",
        "\n",
        "!wget https://s3.amazonaws.com/dl4j-distribution/GoogleNews-vectors-negative300.bin.gz\n",
        "!gunzip GoogleNews-vectors-negative300.bin"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-07-24 12:54:45--  https://s3.amazonaws.com/dl4j-distribution/GoogleNews-vectors-negative300.bin.gz\n",
            "Resolving s3.amazonaws.com (s3.amazonaws.com)... 52.216.136.77\n",
            "Connecting to s3.amazonaws.com (s3.amazonaws.com)|52.216.136.77|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1647046227 (1.5G) [application/x-gzip]\n",
            "Saving to: ‘GoogleNews-vectors-negative300.bin.gz’\n",
            "\n",
            "GoogleNews-vectors- 100%[===================>]   1.53G  45.3MB/s    in 36s     \n",
            "\n",
            "2020-07-24 12:55:21 (43.8 MB/s) - ‘GoogleNews-vectors-negative300.bin.gz’ saved [1647046227/1647046227]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AZ_HeKRI9_7l",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "39272fcd-4d7a-4fc4-d810-5a01879ee8cd"
      },
      "source": [
        "# Try Word2Vec with Gensim\n",
        "\n",
        "import gensim\n",
        "\n",
        "# Load pretrained vectors from Google\n",
        "model = gensim.models.KeyedVectors.load_word2vec_format('GoogleNews-vectors-negative300.bin', binary=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/smart_open/smart_open_lib.py:254: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n",
            "  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bT-yiT9L_c7b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "outputId": "c1ef95e5-d7d2-40de-a820-dc2bad0aa6ad"
      },
      "source": [
        "king = model['king']\n",
        "print(king.shape)\n",
        "print(king[:10])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(300,)\n",
            "[ 0.12597656  0.02978516  0.00860596  0.13964844 -0.02563477 -0.03613281\n",
            "  0.11181641 -0.19824219  0.05126953  0.36328125]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JBznpSDbAAJx",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 89
        },
        "outputId": "7d18b770-5e98-4fb2-d1c0-b884f9d8d0d7"
      },
      "source": [
        "# king - man + woman = queen\n",
        "print(model.most_similar(positive=['woman', 'king'], negative=['man'])[:3])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/gensim/matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
            "  if np.issubdtype(vec.dtype, np.int):\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[('queen', 0.7118192911148071), ('monarch', 0.6189674139022827), ('princess', 0.5902431011199951)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3ckykNCjA-UP",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        },
        "outputId": "112b63a6-ed2a-4483-a3ee-7f44cbceda7c"
      },
      "source": [
        "print(model.doesnt_match(\"breakfast robot dinner lunch\".split()))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "robot\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/gensim/models/keyedvectors.py:895: FutureWarning: arrays to stack must be passed as a \"sequence\" type such as list or tuple. Support for non-sequence iterables such as generators is deprecated as of NumPy 1.16 and will raise an error in the future.\n",
            "  vectors = vstack(self.word_vec(word, use_norm=True) for word in used_words).astype(REAL)\n",
            "/usr/local/lib/python3.6/dist-packages/gensim/matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
            "  if np.issubdtype(vec.dtype, np.int):\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pb121-XFBBc9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 89
        },
        "outputId": "e79a6108-6203-4eaa-ec8c-6ab2d07dad8e"
      },
      "source": [
        "print(model.similarity('woman', 'man'))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.76640123\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/gensim/matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
            "  if np.issubdtype(vec.dtype, np.int):\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YVL0I1qBBDcg",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 89
        },
        "outputId": "01a68671-ea28-480d-8ee7-02f6b3cde335"
      },
      "source": [
        "print(model.similarity('king', 'woman'))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.12847973\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/gensim/matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
            "  if np.issubdtype(vec.dtype, np.int):\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NEFSugKAFXeB"
      },
      "source": [
        "Another word embedding method is **Glove** (“Global Vectors”). It is based on matrix factorization techniques on the word-context matrix. It first constructs a large matrix of (words x context) co-occurrence information, i.e. for each “word” (the rows), you count how frequently we see this word in some “context” (the columns) in a large corpus. Then this matrix is factorized to a lower-dimensional (word x features) matrix, where each row now stores a vector representation for each word. In general, this is done by minimizing a “reconstruction loss”. This loss tries to find the lower-dimensional representations which can explain most of the variance in the high-dimensional data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "27udJLwcbVLv",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 593
        },
        "outputId": "bfbad730-8876-4f99-d68f-912d03c8742b"
      },
      "source": [
        "# Try Glove word embeddings with Spacy\n",
        "\n",
        "!python3 -m spacy download en_core_web_lg"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting en_core_web_lg==2.2.5\n",
            "\u001b[?25l  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_lg-2.2.5/en_core_web_lg-2.2.5.tar.gz (827.9MB)\n",
            "\u001b[K     |████████████████████████████████| 827.9MB 1.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: spacy>=2.2.2 in /usr/local/lib/python3.6/dist-packages (from en_core_web_lg==2.2.5) (2.2.4)\n",
            "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_lg==2.2.5) (1.0.2)\n",
            "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_lg==2.2.5) (0.4.1)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_lg==2.2.5) (1.0.0)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_lg==2.2.5) (1.18.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_lg==2.2.5) (1.0.2)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_lg==2.2.5) (4.41.1)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_lg==2.2.5) (2.0.3)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_lg==2.2.5) (1.1.3)\n",
            "Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_lg==2.2.5) (7.4.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_lg==2.2.5) (49.1.0)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_lg==2.2.5) (3.0.2)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_lg==2.2.5) (0.7.1)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_lg==2.2.5) (2.23.0)\n",
            "Requirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_lg==2.2.5) (1.7.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_lg==2.2.5) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_lg==2.2.5) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_lg==2.2.5) (2020.6.20)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_lg==2.2.5) (2.10)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_lg==2.2.5) (3.1.0)\n",
            "Building wheels for collected packages: en-core-web-lg\n",
            "  Building wheel for en-core-web-lg (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for en-core-web-lg: filename=en_core_web_lg-2.2.5-cp36-none-any.whl size=829180944 sha256=71f23fa6190b30d98a867203431231cf407f0b49982cdc0a9b75a0424c66772b\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-3xjaaj18/wheels/2a/c1/a6/fc7a877b1efca9bc6a089d6f506f16d3868408f9ff89f8dbfc\n",
            "Successfully built en-core-web-lg\n",
            "Installing collected packages: en-core-web-lg\n",
            "Successfully installed en-core-web-lg-2.2.5\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the model via spacy.load('en_core_web_lg')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LkURcwd5LJUp",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 208
        },
        "outputId": "ac9ea4c3-a754-4517-dc6c-e6d05d5651cc"
      },
      "source": [
        "import spacy\n",
        "# Load the spacy model that you have installed\n",
        "import en_core_web_lg\n",
        "nlp = en_core_web_lg.load()\n",
        "# process a sentence using the model\n",
        "doc = nlp(\"man king stands on the carpet and sees woman queen\")\n",
        "# Get the vector for 'king':\n",
        "doc[1].vector[0:50]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 0.31542  , -0.35068  ,  0.42923  , -0.53825  , -0.1848   ,\n",
              "       -0.31082  ,  0.29196  , -0.7103   , -0.23867  ,  1.8471   ,\n",
              "       -0.36446  , -0.51282  ,  0.1221   ,  0.38909  , -0.073204 ,\n",
              "        0.035462 ,  0.33289  ,  0.66466  ,  0.027175 ,  0.42021  ,\n",
              "       -0.1452   ,  0.37991  , -0.6052   ,  0.10695  , -0.64716  ,\n",
              "       -0.010739 , -0.39754  ,  0.38857  , -0.20134  ,  0.69813  ,\n",
              "       -0.32411  ,  0.73085  , -0.1093   , -0.23511  ,  0.18482  ,\n",
              "       -0.11595  , -0.71003  , -0.22974  , -0.41979  ,  0.0081004,\n",
              "       -0.10504  , -0.44802  , -0.073928 , -0.4238   ,  0.28482  ,\n",
              "       -0.074517 ,  0.098161 ,  0.64602  , -0.25832  , -0.020452 ],\n",
              "      dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hI-998SUfAx-"
      },
      "source": [
        "Find similarity between King and Queen (higher value is better)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K34HpkmWaEqV",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "b984ce6c-f825-44a5-e2d4-41465396e7dc"
      },
      "source": [
        "doc[1].similarity(doc[9])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.72526103"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FXm7aeh4hES5"
      },
      "source": [
        "Find similarity between King and carpet "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vSqwqBrUcwMB",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "db19cb1d-29c0-45a2-a556-78ecf3f72f8c"
      },
      "source": [
        "doc[1].similarity(doc[5])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.20431946"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YHsyuyS3h65C"
      },
      "source": [
        "Check if king - man + woman = queen. We will multiply vectors for 'man' and 'woman' by two, because subtracting the vector for 'man' and adding the vector for 'woman' will do little to the original vector for “king”, likely because those “man” and “woman” are related themselves."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IXQ6uvkHh2bA"
      },
      "source": [
        "v =  doc[1].vector - (doc[0].vector*2) + (doc[8].vector*2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bfd7cpLWi0FS"
      },
      "source": [
        "from scipy.spatial import distance\n",
        "import numpy as np\n",
        "\n",
        "# Format the vocabulary for use in the distance function\n",
        "vectors = [token.vector for token in doc]\n",
        "vectors = np.array(vectors)\n",
        "\n",
        "# Find the closest word below \n",
        "closest_index = distance.cdist(np.expand_dims(v, axis = 0), vectors, metric = 'cosine').argmin()\n",
        "output_word = doc[closest_index].text\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AjVLpbCG9829",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "5c6f0e75-ccb5-451b-d6ad-b55d0314eb98"
      },
      "source": [
        "output_word"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'queen'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wwntpvV54Mc4"
      },
      "source": [
        "## FastText\n",
        "\n",
        "[FastText](https://github.com/facebookresearch/fastText) is an extension of word2vec. FastText was developed by the team of Tomas Mikolov who proposed the word2vec framework in 2013.\n",
        "\n",
        "The main improvement of FastText over the original word2vec vectors is the inclusion of character [n-grams](https://en.wikipedia.org/wiki/N-gram), which allows computing word representations for words that did not appear in the training data (“out-of-vocabulary” words)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s8sfT_Z24MDw",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 159
        },
        "outputId": "4ea00fbf-2b88-4e0d-e649-4be21f02be40"
      },
      "source": [
        "!pip install Cython --install-option=\"--no-cython-compile\"\n",
        "!pip install fasttext"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/pip/_internal/commands/install.py:283: UserWarning: Disabling all use of wheels due to the use of --build-options / --global-options / --install-options.\n",
            "  cmdoptions.check_install_build_global(options)\n",
            "Requirement already satisfied: Cython in /usr/local/lib/python3.6/dist-packages (0.29.21)\n",
            "Requirement already satisfied: fasttext in /usr/local/lib/python3.6/dist-packages (0.9.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from fasttext) (1.18.5)\n",
            "Requirement already satisfied: setuptools>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from fasttext) (49.1.0)\n",
            "Requirement already satisfied: pybind11>=2.2 in /usr/local/lib/python3.6/dist-packages (from fasttext) (2.5.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gu6wVBQ89-kd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "14290f95-3f78-4635-e38d-4e5a9127b1f8"
      },
      "source": [
        "# download pre-trained language word vectors from one of 157 languges  https://fasttext.cc/docs/en/crawl-vectors.html\n",
        "# it will take some time, about 5 minutes\n",
        "import fasttext\n",
        "import fasttext.util\n",
        "fasttext.util.download_model('en', if_exists='ignore')  # English\n",
        "ft = fasttext.load_model('cc.en.300.bin')\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FnJKqcnl7l_L",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "3fbb336f-766a-4549-e49a-382b5bb51f5b"
      },
      "source": [
        "ft.get_word_vector('king').shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(300,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b3Dv2Fun_ExK"
      },
      "source": [
        "Test model ability to create vectors for unknown words."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Om1eNJ-_h-J",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "dd36b8bf-a149-4a28-d758-1b0be5c2d378"
      },
      "source": [
        "'king' in ft.words"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "etfyb0xl--1M",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "cc2152cb-83f1-4054-9395-65ea8549d475"
      },
      "source": [
        "'burgerking' in ft.words"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kMR5VDgd_Pfg",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "be006021-6626-423c-82bb-152afa617a2a"
      },
      "source": [
        "'king-warrior' in ft.words"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UTLZvg5e_cBQ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 191
        },
        "outputId": "f53789e5-9f5f-4769-8660-86f21c949678"
      },
      "source": [
        "ft.get_nearest_neighbors('king')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(0.7550359964370728, 'kings'),\n",
              " (0.7068519592285156, 'queen'),\n",
              " (0.7060439586639404, 'king-'),\n",
              " (0.6811205148696899, 'king.'),\n",
              " (0.660710871219635, 'king.The'),\n",
              " (0.6591265797615051, 'King'),\n",
              " (0.6495252251625061, 'prince'),\n",
              " (0.6278106570243835, '-king'),\n",
              " (0.6183920502662659, 'monarch'),\n",
              " (0.6070184707641602, 'queen-mother')]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D7S0lXL0_1D7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 191
        },
        "outputId": "91aeb714-c0cc-4908-bcf8-1a31a0b89f83"
      },
      "source": [
        "ft.get_nearest_neighbors('burgerking')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(0.6571484208106995, 'mcdonalds'),\n",
              " (0.643631100654602, 'tacobell'),\n",
              " (0.6353889107704163, 'macdonalds'),\n",
              " (0.6343632340431213, 'Mcdonalds'),\n",
              " (0.6275104284286499, 'mcds'),\n",
              " (0.6220166087150574, 'pizzahut'),\n",
              " (0.6129778623580933, 'arbys'),\n",
              " (0.6086134314537048, 'BurgerKing'),\n",
              " (0.592319667339325, 'applebees'),\n",
              " (0.5817458629608154, 'wendys')]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "08DO8xhs_81M",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 332
        },
        "outputId": "f1187170-314b-4e1a-aff1-5d37cd4d5581"
      },
      "source": [
        "ft.get_nearest_neighbors('king-warrior')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(0.43609192967414856,\n",
              "  'strachanenlightenmententrepreneursentrepreneurshipenvironmentalismEric'),\n",
              " (0.4255003333091736, 'hunter-warrior'),\n",
              " (0.39559242129325867, 'NinjaPirateZombieRobot'),\n",
              " (0.3859368860721588,\n",
              "  'deblogueroreflejoantecedentesexitlacuachebateysuteindesignableabsorbersexilatifundiosexibrezarsutemultiétnicosexiplinrapobrezarcorrentosoVd.lazadafisiochillidomabrezarsico-chuzaoutcolodrablogueroin'),\n",
              " (0.3846653997898102,\n",
              "  'ResultsLadderTeamsBluesBrumbiesBullsCheetahsChiefsCrusadersForceHighlandersHurricanesJaguaresKingsLionsRebelsRedsSharksStormersSunwolvesWaratahsPlayersTippingFantasyRugby'),\n",
              " (0.37958475947380066,\n",
              "  'FriendsHungryForAppsSharewareOnSaleDonationCoderGhacks'),\n",
              " (0.3776894211769104,\n",
              "  'ESTATERETAILCONSUMERPHONESCARSBIKESAPPSINTERNETTABLETSCOMPUTERSSOCIETYPOLITICSLAWCRIMEENVIRONMENTSCIENCEARTSCELEBRITIESSPORTSSPECIALSFIRST'),\n",
              " (0.37076932191848755,\n",
              "  'ResultsTeamsBroncosBulldogsCowboysDragonsEelsKnightsPanthersRabbitohsRaidersRoostersSea-EaglesSharksStormTigersTitansWarriorsPlayer'),\n",
              " (0.3690166175365448, 'racepro-lifeprofessorsproverbspsychologypublic'),\n",
              " (0.3687925338745117,\n",
              "  'videoAnglicansAtheistsBibleBishopsBloggingBooksBrooklynChaplainsChurchesCNEWAConvertsDeaconsEastern')]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lvE181s7EVO3"
      },
      "source": [
        "## ELMo (Embeddings from Language Models)\n",
        "\n",
        "Unlike traditional word embeddings such as word2vec and GLoVe, the ELMo vector assigned to a token or word depends on current context and is actually a function of the entire sentence containing that word. So, the same word can have different word vectors under different contexts. Also,  ELMo representations are purely character based, so they are not limited to any predefined vocabulary.\n",
        "\n",
        "Description from official site: \n",
        "\n",
        "**[ELMo](https://allennlp.org/elmo)** is a deep contextualized word representation that models both (1) complex characteristics of word use (e.g., syntax and semantics), and (2) how these uses vary across linguistic contexts (i.e., to model polysemy). These word vectors are learned functions of the internal states of a deep bidirectional language model (biLM), which is pre-trained on a large text corpus. They can be easily added to existing models and significantly improve the state of the art across a broad range of challenging NLP problems, including question answering, textual entailment and sentiment analysis. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3ZBZdmGyRAHd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "965b2db3-9162-4d83-a54f-a9254ff5e569"
      },
      "source": [
        "# use tensorflow 1.x for ELMo, because trere are still no ELMo for tensorflow 2.0\n",
        "\n",
        "%tensorflow_version 1.x"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow 1.x selected.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T5vfQ_W2ABqG"
      },
      "source": [
        "import tensorflow_hub as hub\n",
        "import tensorflow as tf"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cud78zEfKJNy"
      },
      "source": [
        "# Download pretrained ELMo model from Tensorflow Hub https://tfhub.dev/google/elmo/3\n",
        "\n",
        "elmo = hub.Module(\"https://tfhub.dev/google/elmo/3\", trainable=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GW5eWPqCKOFz",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 106
        },
        "outputId": "4ba44ce9-9816-4623-f300-d441dfaaf8f1"
      },
      "source": [
        "sentences =  \\\n",
        "['king arthur, also called arthur or aathur pendragon, legendary british king who appears in a cycle of \\\n",
        "medieval romances (known as the matter of britain) as the sovereign of a knightly fellowship of the round table.', \n",
        "'it is not certain how these legends originated or whether the figure of arthur was based on a historical person.', \n",
        "'the legend possibly originated either in wales or in those parts of northern britain inhabited by brythonic-speaking celts.', \n",
        "'for a fuller treatment of the stories about king arthur, see also arthurian legend.']\n",
        "\n",
        "sentences"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['king arthur, also called arthur or aathur pendragon, legendary british king who appears in a cycle of medieval romances (known as the matter of britain) as the sovereign of a knightly fellowship of the round table.',\n",
              " 'it is not certain how these legends originated or whether the figure of arthur was based on a historical person.',\n",
              " 'the legend possibly originated either in wales or in those parts of northern britain inhabited by brythonic-speaking celts.',\n",
              " 'for a fuller treatment of the stories about king arthur, see also arthurian legend.']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2J2HsCMlCPk6"
      },
      "source": [
        "In order to send sentences to the model we need to split them into the arrays of words and pad arrays to the same length. Also we will create 'mask' array, that will show whether element is a real word or a padding symbol (in our case - '_'). We will use 'mask' array for visualization later, to show only real words. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "in6aekmEUMsZ"
      },
      "source": [
        "words = []\n",
        "mask = []\n",
        "masked_words = []\n",
        "\n",
        "for sent in sentences:\n",
        "  splitted = sent.split()\n",
        "  for i in range(36):\n",
        "    try:\n",
        "      words.append(splitted[i])\n",
        "    except:\n",
        "      words.append('_')\n",
        "\n",
        "for word in words:\n",
        "  if word == \"_\":\n",
        "    mask.append(False)\n",
        "  else:\n",
        "    mask.append(True)\n",
        "    masked_words.append(word)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ruJQINKCBHhL",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "e829a9bb-2402-4ed6-edf9-fbb9dd9ea111"
      },
      "source": [
        "len(masked_words)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "88"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qkDSfBYdJFC_"
      },
      "source": [
        "Create embeddings with ELMo:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LoEjgebFMopG",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "d5859834-f96c-4ae7-984c-56691ad0cd2f"
      },
      "source": [
        "embeddings = elmo(\n",
        "    sentences,\n",
        "    signature=\"default\",\n",
        "    as_dict=True)[\"elmo\"]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZO-fH5ewJLQq"
      },
      "source": [
        "Convert Tensorflow tensors to numpy array."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QrfigfFxNef1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "cbb1b586-5826-4d83-ee4b-66d2cbd3b580"
      },
      "source": [
        "%%time\n",
        "with tf.Session() as sess:\n",
        "  sess.run(tf.global_variables_initializer())\n",
        "  sess.run(tf.tables_initializer())\n",
        "  x = sess.run(embeddings)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 4.84 s, sys: 540 ms, total: 5.38 s\n",
            "Wall time: 3.53 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iUSvgkuZOILL",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "35d208a7-5482-4117-c37e-dbbb7fd9cb75"
      },
      "source": [
        "x.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(4, 36, 1024)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nf_0UouAS4-i",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "aa4be247-5da9-4370-a643-edfe81f3e37b"
      },
      "source": [
        "embs = x.reshape(-1, 1024)\n",
        "embs.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(144, 1024)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k7XZpPesCquG",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "899ea5cd-c666-4024-f852-e05d731c7ea8"
      },
      "source": [
        "masked_embs = embs[mask]\n",
        "masked_embs.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(88, 1024)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bubmY1JNSNyy"
      },
      "source": [
        "Visualize embeddings using PCA"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cg7utRgbSBA2"
      },
      "source": [
        "from sklearn.decomposition import PCA\n",
        "\n",
        "pca = PCA(n_components=10)\n",
        "y = pca.fit_transform(masked_embs)\n",
        "\n",
        "from sklearn.manifold import TSNE\n",
        "\n",
        "y = TSNE(n_components=2).fit_transform(y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "efqZ1Xy2STHm"
      },
      "source": [
        "import plotly as py\n",
        "import plotly.graph_objs as go\n",
        "\n",
        "\n",
        "data = [\n",
        "    go.Scatter(\n",
        "        x=[i[0] for i in y],\n",
        "        y=[i[1] for i in y],\n",
        "        mode='markers',\n",
        "        text=[i for i in masked_words],\n",
        "    marker=dict(\n",
        "        size=16,\n",
        "        color = [len(i) for i in masked_words], #set color equal to a variable\n",
        "        opacity= 0.8,\n",
        "        colorscale='Viridis',\n",
        "        showscale=False\n",
        "    )\n",
        "    )\n",
        "]\n",
        "layout = go.Layout()\n",
        "layout = dict(\n",
        "              yaxis = dict(zeroline = False),\n",
        "              xaxis = dict(zeroline = False)\n",
        "             )\n",
        "fig = go.Figure(data=data, layout=layout)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BU7uQvt7GWo-",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        },
        "outputId": "a8dd6956-dd85-4bfe-e6bf-14ce2d48f28b"
      },
      "source": [
        "fig.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>\n",
              "            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>\n",
              "                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script src=\"https://cdn.plot.ly/plotly-latest.min.js\"></script>    \n",
              "            <div id=\"8df3b0dd-bd8d-4146-b8c7-b4e9a84a0684\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>\n",
              "            <script type=\"text/javascript\">\n",
              "                \n",
              "                    window.PLOTLYENV=window.PLOTLYENV || {};\n",
              "                    \n",
              "                if (document.getElementById(\"8df3b0dd-bd8d-4146-b8c7-b4e9a84a0684\")) {\n",
              "                    Plotly.newPlot(\n",
              "                        '8df3b0dd-bd8d-4146-b8c7-b4e9a84a0684',\n",
              "                        [{\"marker\": {\"color\": [4, 7, 4, 6, 6, 2, 6, 10, 9, 7, 4, 3, 7, 2, 1, 5, 2, 8, 8, 6, 2, 3, 6, 2, 8, 2, 3, 9, 2, 1, 8, 10, 2, 3, 5, 6, 2, 2, 3, 7, 3, 5, 7, 10, 2, 7, 3, 6, 2, 6, 3, 5, 2, 1, 10, 7, 3, 6, 8, 10, 6, 2, 5, 2, 2, 5, 5, 2, 8, 7, 9, 2, 18, 6, 3, 1, 6, 9, 2, 3, 7, 5, 4, 7, 3, 4, 9, 7], \"colorscale\": [[0.0, \"#440154\"], [0.1111111111111111, \"#482878\"], [0.2222222222222222, \"#3e4989\"], [0.3333333333333333, \"#31688e\"], [0.4444444444444444, \"#26828e\"], [0.5555555555555556, \"#1f9e89\"], [0.6666666666666666, \"#35b779\"], [0.7777777777777778, \"#6ece58\"], [0.8888888888888888, \"#b5de2b\"], [1.0, \"#fde725\"]], \"opacity\": 0.8, \"showscale\": false, \"size\": 16}, \"mode\": \"markers\", \"text\": [\"king\", \"arthur,\", \"also\", \"called\", \"arthur\", \"or\", \"aathur\", \"pendragon,\", \"legendary\", \"british\", \"king\", \"who\", \"appears\", \"in\", \"a\", \"cycle\", \"of\", \"medieval\", \"romances\", \"(known\", \"as\", \"the\", \"matter\", \"of\", \"britain)\", \"as\", \"the\", \"sovereign\", \"of\", \"a\", \"knightly\", \"fellowship\", \"of\", \"the\", \"round\", \"table.\", \"it\", \"is\", \"not\", \"certain\", \"how\", \"these\", \"legends\", \"originated\", \"or\", \"whether\", \"the\", \"figure\", \"of\", \"arthur\", \"was\", \"based\", \"on\", \"a\", \"historical\", \"person.\", \"the\", \"legend\", \"possibly\", \"originated\", \"either\", \"in\", \"wales\", \"or\", \"in\", \"those\", \"parts\", \"of\", \"northern\", \"britain\", \"inhabited\", \"by\", \"brythonic-speaking\", \"celts.\", \"for\", \"a\", \"fuller\", \"treatment\", \"of\", \"the\", \"stories\", \"about\", \"king\", \"arthur,\", \"see\", \"also\", \"arthurian\", \"legend.\"], \"type\": \"scatter\", \"x\": [0.41210001707077026, 0.16856873035430908, -0.9346179366111755, -1.2107985019683838, -0.5519995093345642, -1.1851505041122437, -0.48707231879234314, -0.4197627902030945, -0.14709356427192688, -0.1313914805650711, 0.03481362387537956, -1.595349669456482, -2.1187100410461426, -3.0670156478881836, 2.4406158924102783, 2.646681070327759, -3.8184311389923096, 0.3785867393016815, 1.4990894794464111, -1.659199833869934, -2.6662468910217285, 2.3300583362579346, 3.6224722862243652, -4.129705905914307, 1.5929350852966309, -2.5977485179901123, 2.70646333694458, 2.3741674423217773, -4.711695194244385, 3.3402366638183594, 2.561197519302368, 2.5904629230499268, -4.620512008666992, 3.3115992546081543, 2.8636772632598877, 6.8428802490234375, -0.2317529320716858, -0.9603851437568665, -1.0134024620056152, -0.4363984763622284, 0.3216626048088074, 1.1067835092544556, 3.5748684406280518, -6.673468112945557, -3.2302420139312744, 0.4668300151824951, 1.3408669233322144, 3.2647416591644287, -3.656322717666626, 0.510547935962677, -3.3567965030670166, -4.412590026855469, -3.8549554347991943, 2.073336362838745, 0.5783870220184326, 6.828091621398926, 0.8170522451400757, 3.4537429809570312, -3.760432004928589, -6.589444160461426, -5.239609718322754, -5.392632484436035, -3.3525309562683105, -5.701033592224121, -5.469233989715576, -4.476229190826416, -4.1920671463012695, -5.824431419372559, -3.8241145610809326, -3.2284274101257324, -5.711629867553711, -5.024847507476807, -2.628439426422119, 6.823374271392822, -1.3461105823516846, 0.4766392707824707, 0.4945864975452423, 0.4913124740123749, -1.9969805479049683, -0.13832953572273254, 0.8112277984619141, -1.641340970993042, 0.5785964727401733, 0.7818183302879333, -1.1115912199020386, -0.9541998505592346, 0.7594422101974487, 6.839396953582764], \"y\": [-1.3007562160491943, 0.43276289105415344, 4.723144054412842, 4.123634338378906, 0.9832426905632019, 3.1039559841156006, 0.7318893671035767, 0.33999574184417725, 1.3465256690979004, 0.06793642789125443, -1.0552581548690796, 4.384794235229492, 4.866325855255127, 6.552412509918213, 6.9441819190979, 2.843627452850342, 7.477388381958008, 2.5772171020507812, 2.85786771774292, 5.206407070159912, 6.1940107345581055, 6.641654014587402, 2.634871244430542, 7.935760498046875, 3.423670530319214, 6.144289970397949, 6.620800971984863, 4.229517459869385, 8.466382026672363, 6.386110782623291, 4.279930114746094, 3.658048391342163, 8.1876802444458, 6.594329357147217, 3.907144546508789, 4.940546035766602, 7.114902973175049, 7.01444673538208, 7.3055548667907715, 7.731413841247559, 8.45400333404541, 8.766210556030273, 0.8307616710662842, 3.057466983795166, 4.707949161529541, 8.015393257141113, 8.081940650939941, 1.4650630950927734, 7.703039646148682, 1.570391058921814, 4.9389448165893555, 4.130980014801025, 6.329981803894043, 7.418156147003174, 3.221735715866089, 4.981595039367676, 8.515816688537598, 1.000065803527832, 4.285880088806152, 3.1737444400787354, 4.424729347229004, 5.422244548797607, 1.2320315837860107, 4.687435626983643, 5.657644271850586, 2.2401299476623535, 1.5606796741485596, 6.377060890197754, 0.9491952061653137, 1.3414872884750366, 4.312410354614258, 6.00209379196167, 1.7030752897262573, 4.992663860321045, 8.654529571533203, 9.974198341369629, 11.158977508544922, 11.310213088989258, 9.400076866149902, 9.32914924621582, 5.582316875457764, 9.149798393249512, -1.417651891708374, 0.5659083127975464, 5.920724391937256, 5.68674898147583, 1.0198122262954712, 4.941398620605469]}],\n",
              "                        {\"template\": {\"data\": {\"bar\": [{\"error_x\": {\"color\": \"#2a3f5f\"}, \"error_y\": {\"color\": \"#2a3f5f\"}, \"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"bar\"}], \"barpolar\": [{\"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"barpolar\"}], \"carpet\": [{\"aaxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"baxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"type\": \"carpet\"}], \"choropleth\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"choropleth\"}], \"contour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"contour\"}], \"contourcarpet\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"contourcarpet\"}], \"heatmap\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmap\"}], \"heatmapgl\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmapgl\"}], \"histogram\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"histogram\"}], \"histogram2d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2d\"}], \"histogram2dcontour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2dcontour\"}], \"mesh3d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"mesh3d\"}], \"parcoords\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"parcoords\"}], \"pie\": [{\"automargin\": true, \"type\": \"pie\"}], \"scatter\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter\"}], \"scatter3d\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter3d\"}], \"scattercarpet\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattercarpet\"}], \"scattergeo\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergeo\"}], \"scattergl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergl\"}], \"scattermapbox\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattermapbox\"}], \"scatterpolar\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolar\"}], \"scatterpolargl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolargl\"}], \"scatterternary\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterternary\"}], \"surface\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"surface\"}], \"table\": [{\"cells\": {\"fill\": {\"color\": \"#EBF0F8\"}, \"line\": {\"color\": \"white\"}}, \"header\": {\"fill\": {\"color\": \"#C8D4E3\"}, \"line\": {\"color\": \"white\"}}, \"type\": \"table\"}]}, \"layout\": {\"annotationdefaults\": {\"arrowcolor\": \"#2a3f5f\", \"arrowhead\": 0, \"arrowwidth\": 1}, \"coloraxis\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"colorscale\": {\"diverging\": [[0, \"#8e0152\"], [0.1, \"#c51b7d\"], [0.2, \"#de77ae\"], [0.3, \"#f1b6da\"], [0.4, \"#fde0ef\"], [0.5, \"#f7f7f7\"], [0.6, \"#e6f5d0\"], [0.7, \"#b8e186\"], [0.8, \"#7fbc41\"], [0.9, \"#4d9221\"], [1, \"#276419\"]], \"sequential\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"sequentialminus\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]]}, \"colorway\": [\"#636efa\", \"#EF553B\", \"#00cc96\", \"#ab63fa\", \"#FFA15A\", \"#19d3f3\", \"#FF6692\", \"#B6E880\", \"#FF97FF\", \"#FECB52\"], \"font\": {\"color\": \"#2a3f5f\"}, \"geo\": {\"bgcolor\": \"white\", \"lakecolor\": \"white\", \"landcolor\": \"#E5ECF6\", \"showlakes\": true, \"showland\": true, \"subunitcolor\": \"white\"}, \"hoverlabel\": {\"align\": \"left\"}, \"hovermode\": \"closest\", \"mapbox\": {\"style\": \"light\"}, \"paper_bgcolor\": \"white\", \"plot_bgcolor\": \"#E5ECF6\", \"polar\": {\"angularaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"radialaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"scene\": {\"xaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"yaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"zaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}}, \"shapedefaults\": {\"line\": {\"color\": \"#2a3f5f\"}}, \"ternary\": {\"aaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"baxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"caxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"title\": {\"x\": 0.05}, \"xaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}, \"yaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}}}, \"xaxis\": {\"zeroline\": false}, \"yaxis\": {\"zeroline\": false}},\n",
              "                        {\"responsive\": true}\n",
              "                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('8df3b0dd-bd8d-4146-b8c7-b4e9a84a0684');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })\n",
              "                };\n",
              "                \n",
              "            </script>\n",
              "        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ns4h9haN15DG"
      },
      "source": [
        "## Transformers\n",
        "\n",
        "At last it's time for current state-of-the-art approach - Transformers. Famous [GPT-2](https://openai.com/blog/better-language-models/), [BERT](https://github.com/google-research/bert), [CTRL](https://blog.einstein.ai/introducing-a-conditional-transformer-language-model-for-controllable-generation/) are all Transformers-based and produce context-sensitive embeddings like ELMo. But unlike ELMo Transformers do not use [RNN](https://en.wikipedia.org/wiki/Recurrent_neural_network), trey do not require to process words in sentence sequentially one-by-one. All words in the sentence are processed in parallel, this approach speeds up processing and solves [vanishing gradient problem](https://en.wikipedia.org/wiki/Vanishing_gradient_problem).\n",
        "\n",
        "Transformers use the [attention mechanizm](https://arxiv.org/abs/1706.03762) to describe the connections and dependencies of each specific word with all other words in the sentence. This mechanism and the main principles of Transformers described in detail in a beautifully illustrated [article](http://jalammar.github.io/illustrated-transformer/) by Jay Alammar.\n",
        "\n",
        "![alt text](http://jalammar.github.io/images/t/transformer_resideual_layer_norm_3.png) Image from[ http://jalammar.github.io](http://jalammar.github.io/illustrated-transformer/)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zvHAQ0_tINn4"
      },
      "source": [
        "For our example we wil use brilliant [Transformers](https://huggingface.co/transformers/) library, which contains the latest Transformers-based models (such as [BERT](https://huggingface.co/transformers/model_doc/bert.html), [XLNet](https://huggingface.co/transformers/model_doc/xlnet.html), [DialoGPT](https://huggingface.co/transformers/model_doc/dialogpt.html) or [GPT-2](https://huggingface.co/transformers/model_doc/gpt2.html)). \n",
        "\n",
        "Let's make some embeddings with BERT. Firstly we will need to install Transformers library."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y05tZ1HmVuiD",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 627
        },
        "outputId": "833c7de1-4e0e-46cb-8b9d-6a8630a2fd74"
      },
      "source": [
        "!pip install transformers"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting transformers\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/27/3c/91ed8f5c4e7ef3227b4119200fc0ed4b4fd965b1f0172021c25701087825/transformers-3.0.2-py3-none-any.whl (769kB)\n",
            "\u001b[K     |████████████████████████████████| 778kB 4.5MB/s \n",
            "\u001b[?25hCollecting tokenizers==0.8.1.rc1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/40/d0/30d5f8d221a0ed981a186c8eb986ce1c94e3a6e87f994eae9f4aa5250217/tokenizers-0.8.1rc1-cp36-cp36m-manylinux1_x86_64.whl (3.0MB)\n",
            "\u001b[K     |████████████████████████████████| 3.0MB 26.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers) (0.7)\n",
            "Collecting sentencepiece!=0.1.92\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d4/a4/d0a884c4300004a78cca907a6ff9a5e9fe4f090f5d95ab341c53d28cbc58/sentencepiece-0.1.91-cp36-cp36m-manylinux1_x86_64.whl (1.1MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1MB 33.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.41.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from transformers) (20.4)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.18.5)\n",
            "Collecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7d/34/09d19aff26edcc8eb2a01bed8e98f13a1537005d31e95233fd48216eed10/sacremoses-0.0.43.tar.gz (883kB)\n",
            "\u001b[K     |████████████████████████████████| 890kB 22.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2020.6.20)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (2.4.7)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (1.15.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (0.16.0)\n",
            "Building wheels for collected packages: sacremoses\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.43-cp36-none-any.whl size=893260 sha256=76991e4939d24ed2935227c6266ef3d73b65be7ca4e5d7f8deb1574bfd0c61da\n",
            "  Stored in directory: /root/.cache/pip/wheels/29/3c/fd/7ce5c3f0666dab31a50123635e6fb5e19ceb42ce38d4e58f45\n",
            "Successfully built sacremoses\n",
            "Installing collected packages: tokenizers, sentencepiece, sacremoses, transformers\n",
            "Successfully installed sacremoses-0.0.43 sentencepiece-0.1.91 tokenizers-0.8.1rc1 transformers-3.0.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KyvVhedCO77-"
      },
      "source": [
        "Now we import pytorch, the pretrained BERT model, and a BERT tokenizer, that will do all the needed work of converting sentences into format appropriate for BERT (tokenizing itself and adding special tokens like [SEP] and [CLS])."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SQgQVUWBE3uK",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 66,
          "referenced_widgets": [
            "0b591df097dd452daca79306abcd3f79",
            "fb59e680d06f4d438d7c3e4cea592b75",
            "c45252039ecd464596a5c2ce83b58e02",
            "4d67c47413e74cca9353e304944f5c22",
            "7b97c0edb8f742babe70de9507afb9fe",
            "fcd212aa59fe4e38925c4d57ac45e2d3",
            "92d33031edb04a9f80891cba9dddd9df",
            "a900bc08c9944d8b931c0c64f5371082"
          ]
        },
        "outputId": "d5d94c5d-0877-4fa7-c889-5d0da49c6b16"
      },
      "source": [
        "import torch\n",
        "torch.manual_seed(0)\n",
        "from transformers import BertTokenizer, BertModel\n",
        "\n",
        "import logging\n",
        "import matplotlib.pyplot as plt\n",
        "% matplotlib inline\n",
        "\n",
        "# Load pre-trained model tokenizer (vocabulary)\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "0b591df097dd452daca79306abcd3f79",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=231508.0, style=ProgressStyle(descripti…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RoKGZPu1dnDz"
      },
      "source": [
        "Enter some sentences and tokenize them."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WQiMtrxHPyYz",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 106
        },
        "outputId": "ca5de695-92cf-4f94-b832-7767185722d8"
      },
      "source": [
        "sentences =  \\\n",
        "['king arthur, also called arthur or aathur pendragon, legendary british king who appears in a cycle of \\\n",
        "medieval romances (known as the matter of britain) as the sovereign of a knightly fellowship of the round table.', \n",
        "'it is not certain how these legends originated or whether the figure of arthur was based on a historical person.', \n",
        "'the legend possibly originated either in wales or in those parts of northern britain inhabited by brythonic-speaking celts.', \n",
        "'for a fuller treatment of the stories about king arthur, see also arthurian legend.']\n",
        "\n",
        "sentences"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['king arthur, also called arthur or aathur pendragon, legendary british king who appears in a cycle of medieval romances (known as the matter of britain) as the sovereign of a knightly fellowship of the round table.',\n",
              " 'it is not certain how these legends originated or whether the figure of arthur was based on a historical person.',\n",
              " 'the legend possibly originated either in wales or in those parts of northern britain inhabited by brythonic-speaking celts.',\n",
              " 'for a fuller treatment of the stories about king arthur, see also arthurian legend.']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 211
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dIgUC1H-Qq3s",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "outputId": "1f689acc-f943-4bdf-c531-59d3b0d82809"
      },
      "source": [
        "# Print the original sentence.\n",
        "print(' Original: ', sentences[0][:99])\n",
        "\n",
        "# Print the sentence split into tokens.\n",
        "print('Tokenized: ', tokenizer.tokenize(sentences[0])[:15])\n",
        "\n",
        "# Print the sentence mapped to token ids.\n",
        "print('Token IDs: ', tokenizer.convert_tokens_to_ids(tokenizer.tokenize(sentences[0]))[:15])\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " Original:  king arthur, also called arthur or aathur pendragon, legendary british king who appears in a cycle \n",
            "Tokenized:  ['king', 'arthur', ',', 'also', 'called', 'arthur', 'or', 'aa', '##th', '##ur', 'pen', '##dra', '##gon', ',', 'legendary']\n",
            "Token IDs:  [2332, 4300, 1010, 2036, 2170, 4300, 2030, 9779, 2705, 3126, 7279, 7265, 7446, 1010, 8987]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8CLrBzF0Xor1"
      },
      "source": [
        "Note that some tokens may look like this: ['aa', '##th', '##ur', 'pen', '##dra', '##gon']. This is because of the BERT tokenizer was created with a WordPiece model. This model greedily creates a fixed-size vocabulary of individual characters, subwords, and words that best fits our language data. BERT tokenizer uses vocabulary that contains all English characters plus the ~30,000 most common words and subwords found in the English language corpus the model is trained on. So, if the word is not mentioned in a vocabulary, that words is splitted into subwords and characters.  The two hash signs (##) before some subwords shows that subword is part of a larger word and preceded by another subword.   "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wJj-lGP-W0me"
      },
      "source": [
        "We will use tokenizer.encode_plus function, that will:\n",
        "\n",
        "- Split the sentence into tokens.\n",
        "- Add the special [CLS] and [SEP] tokens.\n",
        "- Map the tokens to their IDs.\n",
        "- Pad or truncate all sentences to the same length.\n",
        "- Create the attention masks which explicitly differentiate real tokens from [PAD] tokens.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CvZPrF5fWzTZ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        },
        "outputId": "fa9113ec-5f04-45d2-bdd7-d1e6d5333f86"
      },
      "source": [
        "# Tokenize all of the sentences and map the tokens to thier word IDs.\n",
        "input_ids = []\n",
        "attention_masks = []\n",
        "tokenized_texts = []\n",
        "\n",
        "\n",
        "for sent in sentences:\n",
        "    encoded_dict = tokenizer.encode_plus(\n",
        "                        sent,                      # Sentence to encode.\n",
        "                        add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
        "                        truncation=True,\n",
        "                        max_length = 48,           # Pad & truncate all sentences.\n",
        "                        pad_to_max_length = True,                        \n",
        "                        return_tensors = 'pt',     # Return pytorch tensors.\n",
        "                   )\n",
        "\n",
        "    # Save tokens from sentence as a separate array. We will use it later to explore and compare embeddings.\n",
        "    marked_text = \"[CLS] \" + sent + \" [SEP]\"\n",
        "    tokenized_texts.append(tokenizer.tokenize(marked_text))\n",
        "    \n",
        "    # Add the encoded sentence to the list.    \n",
        "    input_ids.append(encoded_dict['input_ids'])\n",
        "\n",
        "# Convert the list into tensor.\n",
        "input_ids = torch.cat(input_ids, dim=0)\n",
        "\n",
        "# Print sentence 0, now as a list of IDs.\n",
        "print('Original: ', sentences[0])\n",
        "print('Token IDs:', input_ids[0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Original:  king arthur, also called arthur or aathur pendragon, legendary british king who appears in a cycle of medieval romances (known as the matter of britain) as the sovereign of a knightly fellowship of the round table.\n",
            "Token IDs: tensor([  101,  2332,  4300,  1010,  2036,  2170,  4300,  2030,  9779,  2705,\n",
            "         3126,  7279,  7265,  7446,  1010,  8987,  2329,  2332,  2040,  3544,\n",
            "         1999,  1037,  5402,  1997,  5781,  7472,  2015,  1006,  2124,  2004,\n",
            "         1996,  3043,  1997,  3725,  1007,  2004,  1996, 11074,  1997,  1037,\n",
            "         5000,  2135,  7881,  1997,  1996,  2461,  2795,   102])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l-HG1Chbh2da"
      },
      "source": [
        "**Segment ID**. BERT is trained on and expects sentence pairs using 1s and 0s to distinguish between the two sentences. We will encode each sentence separately so we will just mark each token in each sentence with 1."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0LjE5M-Qfzxg",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "49e0d863-c3e4-43db-b252-e3b54fb8c77c"
      },
      "source": [
        "segments_ids = torch.ones_like(input_ids)\n",
        "segments_ids.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([4, 48])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tAlTfj9nlItq"
      },
      "source": [
        "Now we can call BERT model and finally get embeddings."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xbI_5u3AlEFt"
      },
      "source": [
        "model = BertModel.from_pretrained('bert-base-uncased',\n",
        "                                  output_hidden_states = True, # Whether the model returns all hidden-states.\n",
        "                                  )\n",
        "model.eval();"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zhj427SijVU4"
      },
      "source": [
        "with torch.no_grad():\n",
        "\n",
        "    outputs = model(input_ids, segments_ids)\n",
        "\n",
        "    # Evaluating the model will return a different number of objects based on \n",
        "    # how it's  configured in the `from_pretrained` call earlier. In this case, \n",
        "    # becase we set `output_hidden_states = True`, the third item will be the \n",
        "    # hidden states from all layers. See the documentation for more details:\n",
        "    # https://huggingface.co/transformers/model_doc/bert.html#bertmodel\n",
        "    hidden_states = outputs[2]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nCKyebgprKLG"
      },
      "source": [
        "Let's examine what we've got."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KRgeWRVHrRHK",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        },
        "outputId": "5c1d5193-2ae6-4ab1-b4f9-d8efd1817672"
      },
      "source": [
        "print (\"Number of layers:\", len(hidden_states), \"  (initial embeddings + 12 BERT layers)\")\n",
        "print (\"Number of batches:\", len(hidden_states[0]))\n",
        "print (\"Number of tokens:\", len(hidden_states[0][0]))\n",
        "print (\"Number of hidden units:\", len(hidden_states[0][0][0]))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of layers: 13   (initial embeddings + 12 BERT layers)\n",
            "Number of batches: 4\n",
            "Number of tokens: 48\n",
            "Number of hidden units: 768\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t9ecIgL1mdox",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "8686ec80-255d-4b29-b5df-a5db7f54edcb"
      },
      "source": [
        "# Concatenate the tensors for all layers. We use `stack` here to\n",
        "# create a new dimension in the tensor.\n",
        "token_embeddings = torch.stack(hidden_states, dim=0)\n",
        "\n",
        "token_embeddings.size()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([13, 4, 48, 768])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_YcTplZDq_Ip",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "3ba08442-8a43-43d7-c9d2-b1d87dff47df"
      },
      "source": [
        "# Swap dimensions, so we get tensors in format: [sentence, tokens, hidden layes, features]\n",
        "token_embeddings = token_embeddings.permute(1,2,0,3)\n",
        "\n",
        "token_embeddings.size()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([4, 48, 13, 768])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hm6lbPc2s0k9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "bacc1c87-9555-48c1-ddfc-aa0c3f93e436"
      },
      "source": [
        "# we will use last four hidden layers to create each word embedding\n",
        "\n",
        "processed_embeddings = token_embeddings[:, :, 9:, :]\n",
        "processed_embeddings.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([4, 48, 4, 768])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q908hPTzxnMU",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "3098b4ea-2f8d-4570-aefd-08b91fd51caa"
      },
      "source": [
        "# Concatenate four layers for each token to create embeddings\n",
        "\n",
        "embeddings = torch.reshape(processed_embeddings, (4, 48, -1))\n",
        "embeddings.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([4, 48, 3072])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CgzGSE0UEfGK"
      },
      "source": [
        "Let's examine embeddings for the first sentence. Firstly we need to get ids of tokens we need to compare."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FbTQaukmzM1v",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 868
        },
        "outputId": "ae99c77d-c516-4ea5-d360-7833c65a1739"
      },
      "source": [
        "for i, token_str in enumerate(tokenized_texts[0]):\n",
        "  print (i, token_str)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0 [CLS]\n",
            "1 king\n",
            "2 arthur\n",
            "3 ,\n",
            "4 also\n",
            "5 called\n",
            "6 arthur\n",
            "7 or\n",
            "8 aa\n",
            "9 ##th\n",
            "10 ##ur\n",
            "11 pen\n",
            "12 ##dra\n",
            "13 ##gon\n",
            "14 ,\n",
            "15 legendary\n",
            "16 british\n",
            "17 king\n",
            "18 who\n",
            "19 appears\n",
            "20 in\n",
            "21 a\n",
            "22 cycle\n",
            "23 of\n",
            "24 medieval\n",
            "25 romance\n",
            "26 ##s\n",
            "27 (\n",
            "28 known\n",
            "29 as\n",
            "30 the\n",
            "31 matter\n",
            "32 of\n",
            "33 britain\n",
            "34 )\n",
            "35 as\n",
            "36 the\n",
            "37 sovereign\n",
            "38 of\n",
            "39 a\n",
            "40 knight\n",
            "41 ##ly\n",
            "42 fellowship\n",
            "43 of\n",
            "44 the\n",
            "45 round\n",
            "46 table\n",
            "47 .\n",
            "48 [SEP]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mmunweJ427pw"
      },
      "source": [
        "We can see that word 'king' is places at indexes 1 and 17. We will check distance between embeddings 1 and 17. Also, we will check if embedding for word 'arthur' is closer to king then word 'table'."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NDVo-mBtzi_3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "outputId": "cdb0024d-5354-47e9-d27d-0de59ee95f21"
      },
      "source": [
        "from scipy.spatial.distance import cosine\n",
        " \n",
        "kings = cosine(embeddings[0][1], embeddings[0][17])\n",
        "king_table = cosine(embeddings[0][1], embeddings[0][46])\n",
        "king_archtur = cosine(embeddings[0][2], embeddings[0][1])\n",
        " \n",
        "print('Distance for two kings:  %.2f' % kings)\n",
        "print('Distance from king to table:  %.2f' % king_table)\n",
        "print('Distance from Archtur to king:  %.2f' % king_archtur)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Distance for two kings:  0.21\n",
            "Distance from king to table:  0.73\n",
            "Distance from Archtur to king:  0.40\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qmYn9mPB5hcr"
      },
      "source": [
        "So we see that embeddings for two 'kings' are quite similar but not same, and Archtur is closer to be a king than a table. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1RSA_l9h6Ftz"
      },
      "source": [
        "Things may be simplier with **[simplerepresentations](https://github.com/AliOsm/simplerepresentations)** module. This module does all the work we did earlier - extracts needed hidden states from BERT and creates embeddings in a few lines of code. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "le0O7JeS62P8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "outputId": "6fea8c54-43fa-495c-a064-efc72d3fb8c1"
      },
      "source": [
        "!pip install simplerepresentations"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: simplerepresentations in /usr/local/lib/python3.6/dist-packages (0.0.4)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.6/dist-packages (from simplerepresentations) (3.0.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from simplerepresentations) (4.41.1)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.6/dist-packages (from simplerepresentations) (1.5.1+cu101)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from simplerepresentations) (1.18.5)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers->simplerepresentations) (2019.12.20)\n",
            "Requirement already satisfied: sentencepiece!=0.1.92 in /usr/local/lib/python3.6/dist-packages (from transformers->simplerepresentations) (0.1.91)\n",
            "Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers->simplerepresentations) (0.7)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from transformers->simplerepresentations) (20.4)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.6/dist-packages (from transformers->simplerepresentations) (0.0.43)\n",
            "Requirement already satisfied: tokenizers==0.8.1.rc1 in /usr/local/lib/python3.6/dist-packages (from transformers->simplerepresentations) (0.8.1rc1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers->simplerepresentations) (2.23.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers->simplerepresentations) (3.0.12)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch->simplerepresentations) (0.16.0)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers->simplerepresentations) (2.4.7)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from packaging->transformers->simplerepresentations) (1.15.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers->simplerepresentations) (0.16.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers->simplerepresentations) (7.1.2)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers->simplerepresentations) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers->simplerepresentations) (2020.6.20)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers->simplerepresentations) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers->simplerepresentations) (2.10)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1T01bAY75Mcv",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 168,
          "referenced_widgets": [
            "1ae7a66074b24b30b7b8d47b75104c7f",
            "16a736e460f749c9a1c035723a1ad201",
            "7843040f735546afb64c90602c1c8a0b",
            "596cc22cc85948238fa53d923227f1ae",
            "023206090efd43f3bf81dfddf342e5c1",
            "a750268e28d24240bf36532404abc1fa",
            "98985960e55f438ba8dbbf77c50ed47b",
            "c81ccc42ccb245a3b3c965b237576550",
            "2899a7fc90ab4541af179a63abba0b39",
            "700b9b4369d04c7baa90551057950298",
            "a93285635aef433281557db177e019af",
            "dcf81c767ad84cb9b2c305d1d94743e7",
            "6898eb8c7ccd4bc59ba327b244edf4af",
            "6e779a45d40f408a9a7419a11101e0b4",
            "3108385d70a24cc8a9fde1f4c8c91d19",
            "aea2a412a09f46d2b68a36c23a3577f3"
          ]
        },
        "outputId": "1be20ef2-1abf-4c92-ce39-ea43031caa4b"
      },
      "source": [
        "import torch\n",
        "from simplerepresentations import RepresentationModel\n",
        "torch.manual_seed(0)\n",
        "\n",
        "model_type = 'bert'\n",
        "model_name = 'bert-base-uncased'\n",
        "\n",
        "representation_model = RepresentationModel(\n",
        "\t\tmodel_type=model_type,\n",
        "\t\tmodel_name=model_name,\n",
        "\t\tbatch_size=4,\n",
        "\t\tmax_seq_length=48, # truncate sentences to be less than or equal to 48 tokens\n",
        "\t\tcombination_method='cat', # concatenate the last `last_hidden_to_use` hidden states\n",
        "\t\tlast_hidden_to_use=4 # use the last 4 hidden states to build tokens representations\n",
        "\t)\n",
        "\n",
        "text_a = sentences\n",
        "\n",
        "all_sentences_representations, all_tokens_representations = representation_model(text_a=text_a)\n",
        "\n",
        "print(all_sentences_representations.shape) # (4, 768) => (number of sentences, hidden size)\n",
        "print(all_tokens_representations.shape) # (4, 48, 3072) => (number of sentences, number of tokens, hidden size)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Converting to features started.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1ae7a66074b24b30b7b8d47b75104c7f",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=4.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "2899a7fc90ab4541af179a63abba0b39",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "(4, 768)\n",
            "(4, 48, 3072)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H5hXmpV57wgh"
      },
      "source": [
        "Check distaces between Archtur, king and table."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lu1llFF27eXc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "outputId": "1a126af6-ac4c-4ed4-9d09-b8d39c4ce453"
      },
      "source": [
        "from scipy.spatial.distance import cosine\n",
        "\n",
        "kings = cosine(all_tokens_representations[0][1], all_tokens_representations[0][17])\n",
        "king_table = cosine(all_tokens_representations[0][1], all_tokens_representations[0][46])\n",
        "king_archtur = cosine(all_tokens_representations[0][2], all_tokens_representations[0][1])\n",
        "\n",
        "print('Distance for two kings:  %.2f' % kings)\n",
        "print('Distance from king to table:  %.2f' % king_table)\n",
        "print('Distance from Archtur to king:  %.2f' % king_archtur)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Distance for two kings:  0.21\n",
            "Distance from king to table:  0.73\n",
            "Distance from Archtur to king:  0.40\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w8M5HubwC1BX"
      },
      "source": [
        "Same results, less code."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qMhX6QOORrxq"
      },
      "source": [
        "## Conclusion\n",
        "\n",
        "I hope that after reading this article you have formed an idea of the current approaches to word embeddings and began to understand how to quickly implement these approaches in Python. The world of NLP is diverse and there are many more models and methods for embeddings. In my article I focused on the most common and those that we ourselves often use in our work. You can find additional information in the **References** section."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XxnDjaFYMolw"
      },
      "source": [
        "## References\n",
        "\n",
        "- [BERT Word Embeddings Tutorial](https://mccormickml.com/2019/05/14/BERT-word-embeddings-tutorial/)\n",
        "- [The Illustrated Transformer](http://jalammar.github.io/illustrated-transformer/)\n",
        "- [The Illustrated GPT-2 (Visualizing Transformer Language Models)](http://jalammar.github.io/illustrated-gpt2/) \n",
        "- [FROM Pre-trained Word Embeddings TO Pre-trained Language Models — Focus on BERT](https://towardsdatascience.com/from-pre-trained-word-embeddings-to-pre-trained-language-models-focus-on-bert-343815627598)\n",
        "- [ Make your own Rick Sanchez (bot) with Transformers and DialoGPT fine-tuning](https://towardsdatascience.com/make-your-own-rick-sanchez-bot-with-transformers-and-dialogpt-fine-tuning-f85e6d1f4e30)\n",
        "- [Playing with word vectors](https://medium.com/swlh/playing-with-word-vectors-308ab2faa519) \n",
        "- [Intuitive Guide to Understanding GloVe Embeddings](https://towardsdatascience.com/light-on-math-ml-intuitive-guide-to-understanding-glove-embeddings-b13b4f19c010)\n",
        "- [Word Embeddings in Python with Spacy and Gensim](https://www.shanelynn.ie/word-embeddings-in-python-with-spacy-and-gensim/)\n",
        "- [Brief review of word embedding families (2019) ](https://medium.com/analytics-vidhya/brief-review-of-word-embedding-families-2019-b2bbc601bbfe)\n",
        "- [Word embeddings: exploration, explanation, and exploitation (with code in Python)](https://towardsdatascience.com/word-embeddings-exploration-explanation-and-exploitation-with-code-in-python-5dac99d5d795)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-IXkbDV1kUz7"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}