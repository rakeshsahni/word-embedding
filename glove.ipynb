{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Lets Create interesting NLP project"
      ],
      "metadata": {
        "id": "SCQpbhCdXHqM"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pHdtizR4T1d_"
      },
      "source": [
        "The most commonly used models for word embeddings are [word2vec](https://github.com/dav/word2vec/) and [GloVe](https://nlp.stanford.edu/projects/glove/) which are both unsupervised approaches based on the distributional hypothesis (words that occur in the same contexts tend to have similar meanings).\n",
        "\n",
        "Word2Vec word embeddings are vector representations of words, \n",
        "that are typically learnt by an unsupervised model when fed \n",
        "with large amounts of text as input (e.g. Wikipedia, science, news, articles etc.). These representation of words capture semantic similarity between words among other properties. Word2Vec word embeddings are learnt in a such way, that [distance](https://en.wikipedia.org/wiki/Euclidean_distance) between vectors for words with close meanings (\"king\" and \"queen\" for example) are closer than distance for words with complety different meanings (\"king\" and \"carpet\" for example).\n",
        "\n",
        "![Замещающий текст](https://developers.google.com/machine-learning/crash-course/images/linear-relationships.svg)\n",
        "Image from [developers.google.com](https://developers.google.com/machine-learning/crash-course/embeddings/translating-to-a-lower-dimensional-space)\n",
        "\n",
        "Word2Vec vectors even allow some mathematic operations on vectors. For example, in this operation we are using word2vec vectors for each word:\n",
        "\n",
        "**king - man + woman = queen**"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "word embedding method is Glove (“Global Vectors”). It is based on matrix factorization techniques on the word-context matrix. It first constructs a large matrix of (words x context) co-occurrence information, i.e. for each “word” (the rows), you count how frequently we see this word in some “context” (the columns) in a large corpus. Then this matrix is factorized to a lower-dimensional (word x features) matrix, where each row now stores a vector representation for each word. In general, this is done by minimizing a “reconstruction loss”. This loss tries to find the lower-dimensional representations which can explain most of the variance in the high-dimensional data."
      ],
      "metadata": {
        "id": "DzCAUW7K4KlW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://nlp.stanford.edu/data/glove.42B.300d.zip #https://nlp.stanford.edu/data/glove.6B.zip"
      ],
      "metadata": {
        "id": "Z3LZwuMo7d8g",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "55a8ed61-0496-425c-a590-96db0a4ed233"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-08-08 15:17:17--  https://nlp.stanford.edu/data/glove.42B.300d.zip\n",
            "Resolving nlp.stanford.edu (nlp.stanford.edu)... 171.64.67.140\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: https://downloads.cs.stanford.edu/nlp/data/glove.42B.300d.zip [following]\n",
            "--2022-08-08 15:17:17--  https://downloads.cs.stanford.edu/nlp/data/glove.42B.300d.zip\n",
            "Resolving downloads.cs.stanford.edu (downloads.cs.stanford.edu)... 171.64.64.22\n",
            "Connecting to downloads.cs.stanford.edu (downloads.cs.stanford.edu)|171.64.64.22|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1877800501 (1.7G) [application/zip]\n",
            "Saving to: ‘glove.42B.300d.zip’\n",
            "\n",
            "glove.42B.300d.zip  100%[===================>]   1.75G  5.07MB/s    in 5m 53s  \n",
            "\n",
            "2022-08-08 15:23:11 (5.08 MB/s) - ‘glove.42B.300d.zip’ saved [1877800501/1877800501]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# !unzip /content/glove.6B.zip\n",
        "!unzip /content/glove.42B.300d.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SN9zlJYnEexU",
        "outputId": "0ff5c22f-b7e4-44c1-fa9a-192cfb08f272"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  /content/glove.42B.300d.zip\n",
            "  inflating: glove.42B.300d.txt      \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from gensim.scripts.glove2word2vec import glove2word2vec"
      ],
      "metadata": {
        "id": "DWGLXEsdFYMr"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# glove_input_file = r\"/content/glove.6B.300d.txt\"\n",
        "glove_input_file = r\"/content/glove.42B.300d.txt\"\n",
        "glove_output_file = r\"word2vec.txt\""
      ],
      "metadata": {
        "id": "kxxHFYtQGF6R"
      },
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "glove2word2vec(glove_input_file, glove_output_file)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "therw_31GUHp",
        "outputId": "3c7c0d6c-d408-4b94-8d69-83d3123242ab"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1917494, 300)"
            ]
          },
          "metadata": {},
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from gensim.models import KeyedVectors"
      ],
      "metadata": {
        "id": "3NxHCrL8GhwJ"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = KeyedVectors.load_word2vec_format(glove_output_file, binary=False)"
      ],
      "metadata": {
        "id": "UCdP-l3J1PNv"
      },
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.similarity('go','went')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TEnOdJO21kEw",
        "outputId": "1335c70a-fb38-41e7-b473-90335c91f83a"
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7681654"
            ]
          },
          "metadata": {},
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "print_related function based on cosine similarity"
      ],
      "metadata": {
        "id": "dn18fXT0J_cX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def print_related(word = 'india', topn = 7) : \n",
        "  try : \n",
        "    word = word.lower()\n",
        "    top_wd = model.most_similar(word, topn = topn)\n",
        "    print(f\"{word} related Word : \")\n",
        "    for itm in top_wd : \n",
        "      print(f\"{itm[0]} {round(itm[1]*100, 2)}%\")\n",
        "  except : \n",
        "    print(f\"{word} has spelled mistakes or does not exist...\")"
      ],
      "metadata": {
        "id": "OVrNNoRU4MyY"
      },
      "execution_count": 115,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print_related()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bu5aWZXV3SAO",
        "outputId": "b5e89c24-ade0-4025-bc55-6cc19c1d87f6"
      },
      "execution_count": 117,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "india related Word : \n",
            "delhi 76.45%\n",
            "pakistan 72.87%\n",
            "indian 72.85%\n",
            "mumbai 71.2%\n",
            "bangalore 68.81%\n",
            "chennai 67.87%\n",
            "lanka 66.8%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Surprisingly enough:\n",
        "\n",
        "vector(“France”) - vector(\"Paris\") = answer_vector - vector(\"Rome\")\n",
        "\n",
        "Therefore:\n",
        "\n",
        "vector(“France”) - vector(\"Paris\") + vector(\"Rome\") = answer_vector\n",
        "\n",
        "We’ll look for words close to answer_vector. The answer_vector won’t match “Italy” exactly but it should be close."
      ],
      "metadata": {
        "id": "1MK2A5JL8Igf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def print_analogy(word1 = 'king', word2 = 'man', word3 = 'woman', topn = 1, percentage = False) : \n",
        "  try : \n",
        "    word1 = word1.lower()\n",
        "    word2 = word2.lower()\n",
        "    word3 = word3.lower()\n",
        "    top_wd = model.most_similar(positive=[word2, word3], negative=[word1], topn = topn)\n",
        "    print(f\"{word1} : {word2} :: {word3} : {top_wd[0][0]}\")\n",
        "    if percentage : \n",
        "      for itm in top_wd : \n",
        "        print(f\"{itm[0]} - {round(itm[1]*100, 2)}%\")\n",
        "  except : \n",
        "    print(f\"{word1} | {word2} | {word3} have spelled mistake or does not exist...\")"
      ],
      "metadata": {
        "id": "_L8cLDzU8JTo"
      },
      "execution_count": 133,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 'Paris', 'France', 'Rome'\n",
        "# 'man', 'king', 'woman'\n",
        "# 'walk', 'walked' , 'go'\n",
        "# 'do', 'done' , 'go'\n",
        "# 'quick', 'quickest' , 'far'"
      ],
      "metadata": {
        "id": "QErleAAfAPg1"
      },
      "execution_count": 134,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print_analogy('Paris', 'France', 'Rome', 5, percentage=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kSc3OMQ69Stn",
        "outputId": "ab79bf6d-b799-4291-e22f-6c6cdfc7b025"
      },
      "execution_count": 135,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "paris : france :: rome : italy\n",
            "italy - 72.5%\n",
            "europe - 62.27%\n",
            "greece - 59.68%\n",
            "portugal - 59.45%\n",
            "spain - 59.32%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Not-related word found in a group of words is called ODD\n",
        "exectly same functon doesnt_match"
      ],
      "metadata": {
        "id": "vxsTbDyoSVt0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def doesnt_match(words) : \n",
        "  try : \n",
        "    words = \" \".join(words).lower().split(\" \")\n",
        "    print(model.doesnt_match(words))\n",
        "  except : \n",
        "    print(f\"{words} have spelled mistake or does not exist...\")\n",
        "  # print(model.doesnt_match(\"breakfast robot dinner lunch\".split()))"
      ],
      "metadata": {
        "id": "wJR82FlX9WYP"
      },
      "execution_count": 142,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "fFW2VBUBP86f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "similarity function is return how much percentage related to each other words"
      ],
      "metadata": {
        "id": "3X_dmIgaRKw1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def similarity(word1 = 'woman', word2 = 'man') : \n",
        "  try : \n",
        "    word1 = word1.lower()\n",
        "    word2 = word2.lower()\n",
        "    print(f\"{word1} and {word2} are similar to {round(model.similarity(word1, word2)*100, 2 )} %\")\n",
        "  except : \n",
        "    print(f\"{word1} | {word2} have spelled mistake or does not exist...\")"
      ],
      "metadata": {
        "id": "CfFw_FzGP9cT"
      },
      "execution_count": 151,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "similarity()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8uKJ5ukXMHbC",
        "outputId": "0e7288db-df9f-423c-a896-5799d68d51ff"
      },
      "execution_count": 150,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "woman and man are similar to 80.48 %\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.doesnt_match(['tea','water', 'mango'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        },
        "id": "9A5KJUwXMOmh",
        "outputId": "9051187a-70e1-4324-d34d-2d3d22b7d545"
      },
      "execution_count": 129,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/gensim/models/keyedvectors.py:895: FutureWarning: arrays to stack must be passed as a \"sequence\" type such as list or tuple. Support for non-sequence iterables such as generators is deprecated as of NumPy 1.16 and will raise an error in the future.\n",
            "  vectors = vstack(self.word_vec(word, use_norm=True) for word in used_words).astype(REAL)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'mango'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 129
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# spain called although arms roots\n",
        "# print_related(\"spain\")"
      ],
      "metadata": {
        "id": "_Uev0aMWMznq"
      },
      "execution_count": 173,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print_related('roots')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0iAag5frWe4Y",
        "outputId": "4b98a615-0c4f-4907-e8fd-f9488c413f26"
      },
      "execution_count": 178,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "roots related Word : \n",
            "root 61.04%\n",
            "rooted 58.54%\n",
            "growing 57.53%\n",
            "grow 55.44%\n",
            "stems 53.49%\n",
            "tradition 53.38%\n",
            "origins 53.08%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 'Paris', 'France', 'Rome'\n",
        "# 'man', 'king', 'woman'\n",
        "# 'walk', 'walked' , 'go'\n",
        "# 'do', 'done' , 'go'\n",
        "# 'quick', 'quickest' , 'far'\n",
        "# print_analogy('Paris', 'France', 'Rome', 5, percentage=True)"
      ],
      "metadata": {
        "id": "X98ywvVsR5fr"
      },
      "execution_count": 154,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print_analogy('quick', 'quickest' , 'far', 5, percentage=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i7Gz3GHSWVan",
        "outputId": "0e3a18d6-ee6c-41a1-acc7-0f04a050cfaa"
      },
      "execution_count": 187,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "quick : quickest :: far : fastest\n",
            "fastest - 58.34%\n",
            "arguably - 56.54%\n",
            "safest - 55.08%\n",
            "cleanest - 53.26%\n",
            "shortest - 52.17%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 'breakfast', 'robot', 'dinner', 'lunch'\n",
        "# 'Spain', 'Russia', 'Canada', 'Africa'\n",
        "# 'banana', 'apple', 'rice', 'grape'\n",
        "# 'car', 'plane', 'road', 'train'\n",
        "# 'king','queen', 'prince', 'man'\n",
        "# doesnt_match([])"
      ],
      "metadata": {
        "id": "iSQkQOntSFGi"
      },
      "execution_count": 155,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "doesnt_match(['car', 'plane', 'road', 'train'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_RK-UGfnUNcO",
        "outputId": "02179712-4deb-422b-fa28-a7ae4a333619"
      },
      "execution_count": 192,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "plane\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/gensim/models/keyedvectors.py:895: FutureWarning: arrays to stack must be passed as a \"sequence\" type such as list or tuple. Support for non-sequence iterables such as generators is deprecated as of NumPy 1.16 and will raise an error in the future.\n",
            "  vectors = vstack(self.word_vec(word, use_norm=True) for word in used_words).astype(REAL)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# man woman\n",
        "# boy girl\n",
        "# cat dog\n",
        "# india pakishtan\n",
        "# similarity('king', 'queen')"
      ],
      "metadata": {
        "id": "Z6yvVIAPTolM"
      },
      "execution_count": 156,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "similarity('you', 'me')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lvrx4tO0T-yT",
        "outputId": "6996f77a-6723-4430-af18-772b22cdfd25"
      },
      "execution_count": 197,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "you and me are similar to 77.18 %\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "BpAvyxMBUETT"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "name": "glove.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}